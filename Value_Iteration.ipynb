{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "498f26c3-accf-425c-a85f-a166fe1ca3b9",
   "metadata": {},
   "source": [
    "# pip install gym\n",
    "# pip install pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b624c22-0293-4a76-a9d7-e95cfd808e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb4eddf3-0f2b-4b30-9e36-9311a0d1d49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# render_mode ['human' -> Show The Game ,  'rgb_array' -> do not Show The Game]\n",
    "\n",
    "# is_slippery ['False' -> Deterministic Environment , 'Ture' -> Stochastic Environment ]\n",
    "\n",
    "# Games ['FrozenLake-v1' , 'CartPole-v1']\n",
    "\n",
    "env = gym.make('FrozenLake-v1', render_mode=\"human\" ,is_slippery=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dfce2a5-7fd7-4078-a14a-f9e68369a221",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueIteration():\n",
    "    def __init__(self , env, n_iterations,discount_factor):\n",
    "      self.n_iterations = n_iterations\n",
    "      self.discount_factor = discount_factor\n",
    "      \n",
    "        # num of States in Our Environment\n",
    "      self.num_states = env.observation_space.n\n",
    "        \n",
    "        # num of Actions in Our Environment\n",
    "      self.num_actions = env.action_space.n\n",
    "\n",
    "      # initialize Value of All States with Zero\n",
    "      self.value_table = [0]*self.num_states\n",
    "      self.optimal_policy = [0]*self.num_states\n",
    "\n",
    "    def get_optimal_value(self):\n",
    "      for i in range(self.n_iterations):\n",
    "        \n",
    "          # get Q(s,a) for each State Action pair in the Environment.\n",
    "        for state_index in range(self. num_states):\n",
    "          actions_Q = [0]*self.num_states # [0,0,0,0]\n",
    "          for action in range(self.num_actions):\n",
    "            info_state = env.P[state_index][action]\n",
    "              \n",
    "              # Probability - P(s'|s,a) \n",
    "            prob = np.array([x[0] for x in info_state])\n",
    "              \n",
    "              # Reward -  R(s,a,s') + γ * V_k(s') \n",
    "            R = np.array([x[2] for x in info_state]) + \\\n",
    "              self.discount_factor * np.array([self.value_table[x[1]] for x in info_state])\n",
    "\n",
    "              # get Q for each State Action\n",
    "            Q=sum(prob * R)\n",
    "            actions_Q[action] = Q       \n",
    "              \n",
    "              # get Optimal Value of the state:\n",
    "            self.value_table[state_index] = max(actions_Q)\n",
    "       # print (self.value_table)\n",
    "\n",
    "\n",
    "     # Get optimal policy from the optimal value\n",
    "    def get_optimal_policy(self):\n",
    "      for state_index in range(self.num_states):\n",
    "        action_Q = [0]*self.num_states\n",
    "        for action in range(self.num_actions):\n",
    "          info_state = env.P[state_index][action]\n",
    "           \n",
    "            # Probability - P(s'|s,a) \n",
    "          prob = np.array([x[0] for x in info_state])\n",
    "            # Reward -  R(s,a,s') + γ * V_k(s')\n",
    "          R = np.array([x[2] for x in info_state]) + \\\n",
    "            self.discount_factor * np.array([self.value_table[x[1]] for x in info_state])\n",
    "            # get Q for each State Action\n",
    "          Q = sum(prob * R)\n",
    "          action_Q[action] = Q\n",
    "            # get The Action have Max Value\n",
    "        self.optimal_policy[state_index] = np.argmax(action_Q)\n",
    "      return (self.optimal_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7754ddee-c10f-4320-99cc-74cfb59bdde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-23 07:04:42.791 python[2644:58749] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-07-23 07:04:42.791 python[2644:58749] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    }
   ],
   "source": [
    "# Reset agent For First State [0] in Our Environment\n",
    "cur_state = env.reset() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e86a96b-3733-4aac-9130-06245863d5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iterations = 1000\n",
    "discount = 0.9   # γ [0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c1af27b-bd3e-4964-ad2e-c2d76f5fb743",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = ValueIteration(env,n_iterations,discount)\n",
    "app.get_optimal_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b73951e5-4762-46af-a7df-1b613e21ea49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 1, 0, 1, 0, 1, 0, 2, 1, 1, 0, 0, 2, 2, 0]\n"
     ]
    }
   ],
   "source": [
    "policy = app.get_optimal_policy()\n",
    "print(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "baaab31a-0232-48af-a2db-f81215a3fcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 0  # State 0\n",
    "done = False # Truncated or Terminated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c84f092-8c0e-4fd8-bb65-edff49b2f122",
   "metadata": {},
   "outputs": [],
   "source": [
    "while not done:\n",
    "  t = env.step(int(policy[s]))\n",
    "  s = t[0] # New State (S')\n",
    "  \n",
    "    # Truncated or Terminated\n",
    "    # Terminated -> if this Next_state is Terminal State ?\n",
    "    # Truncated  -> if Agent Finished The Time\n",
    "  done = t[2] or t[3]\n",
    "  env.render()\n",
    "#env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0770a793-556a-4d2f-9f0a-7c0943523e06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509ae634-f921-4ca2-b6c7-ffb20b6860bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
